{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to RAPIDS using the New York City Yellow Taxi Data \n",
    "light on Data Science, heavy on comparisons.\n",
    "\n",
    "This notebook is for the The Toronto Machine Learning Summit, Nov 16 -29, 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes\n",
    "\n",
    "* cudf - for basic ETL and some __statistical analysis__ \n",
    "* cugraph - for some __graph analysis__\n",
    "* cuxfilter - for __visualization__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the libraries\n",
    "import cudf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from collections import OrderedDict\n",
    "import argparse\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import tqdm\n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install tqdm')\n",
    "    import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use Unified Memory (aka managed memory) so that we try and avoid OOM errors \n",
    "# start by importing the RAPIDS Memory Manager and then reinitializing with managed memory turn on\n",
    "import rmm\n",
    "\n",
    "rmm.reinitialize(   \n",
    "    managed_memory=True,        # Use managed memory, this allows for oversubscription of the GPU\n",
    "    pool_allocator=False,       # default is False\n",
    "    devices=0,                  # GPU device IDs to register. By default, registers only GPU 0.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = \"./\"\n",
    "data_dir = \"./nyctaxi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Taxi data\n",
    "\n",
    "if os.path.exists(data_dir) == False:\n",
    "    import nyctaxi_data\n",
    "\n",
    "    print(\"downloading data\")\n",
    "    nyctaxi_data.download_nyctaxi_data([\"2016\"], top_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# cuDF - Accelerated Data Frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of files\n",
    "data_path = top_dir + \"nyctaxi/2016\"\n",
    "\n",
    "files = []\n",
    "\n",
    "for f in sorted(os.listdir(data_path)):\n",
    "    if f[0:6] != 'yellow':\n",
    "        continue\n",
    "        \n",
    "    fname = os.path.join(data_path, f)\n",
    "            \n",
    "    files.append(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pandas(f):\n",
    "    start_t = time.time()\n",
    "    df = pd.read_csv(f)\n",
    "    end_t = time.time() - start_t\n",
    "\n",
    "    return df, end_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cudf(f):\n",
    "    start_t = time.time()\n",
    "    df = cudf.read_csv(f)\n",
    "    end_t = time.time() - start_t\n",
    "\n",
    "    return df, end_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = read_pandas(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with Pandas\n",
    "\n",
    "data = []\n",
    "\n",
    "start_t = time.time()\n",
    "\n",
    "for f in files:\n",
    "    print(\"\\treading \" + f, end = '')\n",
    "    df, t = read_pandas(f)\n",
    "    print(\" ... in time of \" + str(t) + \" seconds\")\n",
    "    data.append(df)\n",
    "  \n",
    "taxi_pdf = pd.concat(data)\n",
    "\n",
    "end_t = time.time()\n",
    "\n",
    "print(f\"loaded {len(taxi_pdf):,} records in {(end_t - start_t):2f}  seconds\")\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with RAPIDS cuDF\n",
    "\n",
    "data = []\n",
    "\n",
    "start_t = time.time()\n",
    "\n",
    "for f in files:\n",
    "    print(\"\\treading \" + f, end = '')\n",
    "    df, t = read_cudf(f)\n",
    "    print(\" ... in time of \" + str(t)+ \" seconds\")\n",
    "    data.append(df)\n",
    "\n",
    "taxi_gdf = cudf.concat(data)\n",
    "\n",
    "end_t = time.time()\n",
    "\n",
    "print(f\"loaded {len(taxi_gdf):,} records in {(end_t - start_t):2f}  seconds\")\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_gdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort Comparisons - Single Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sp = taxi_pdf.sort_values(by='trip_distance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sg = taxi_gdf.sort_values(by='trip_distance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group By - Single Column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbp = taxi_pdf.groupby('passenger_count').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbg = taxi_gdf.groupby('passenger_count').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbg.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"Max fare was ${taxi_pdf['fare_amount'].max():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"Max fare was ${taxi_gdf['fare_amount'].max():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at that huge fare\n",
    "maxf = taxi_gdf['fare_amount'].max()\n",
    "taxi_gdf.query('fare_amount == @maxf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Farthest trip was {taxi_gdf['trip_distance'].max():,} miles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long did it take to drive that distance?\n",
    "maxd= taxi_gdf['trip_distance'].max()\n",
    "taxi_gdf.query('trip_distance == @maxd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change some data types\n",
    "taxi_gdf = taxi_gdf.astype({'tpep_pickup_datetime':'datetime64[ms]', 'tpep_dropoff_datetime':'datetime64[ms]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out records with missing or outlier values\n",
    "query_frags = (\"(fare_amount > 0 and fare_amount < 500) \" +\n",
    "        \"and (passenger_count > 0 and passenger_count < 6) \" +\n",
    "        \"and (pickup_longitude > -75 and pickup_longitude < -73) \" +\n",
    "        \"and (dropoff_longitude > -75 and dropoff_longitude < -73) \" +\n",
    "        \"and (pickup_latitude > 40 and pickup_latitude < 42) \" +\n",
    "        \"and (dropoff_latitude > 40 and dropoff_latitude < 42)\" +\n",
    "        \"and (pickup_latitude != dropoff_latitude) \" +\n",
    "        \"and (pickup_longitude != dropoff_longitude)\"\n",
    "    )\n",
    "\n",
    "taxi_gdf = taxi_gdf.query(query_frags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easier to reference time by YYYY MM DD version a time stamps\n",
    "taxi_gdf['hour']  = taxi_gdf['tpep_pickup_datetime'].dt.hour\n",
    "taxi_gdf['year']  = taxi_gdf['tpep_pickup_datetime'].dt.year\n",
    "taxi_gdf['month'] = taxi_gdf['tpep_pickup_datetime'].dt.month\n",
    "taxi_gdf['day']   = taxi_gdf['tpep_pickup_datetime'].dt.day\n",
    "taxi_gdf['diff']  = taxi_gdf['tpep_dropoff_datetime'].astype('int64') - taxi_gdf['tpep_pickup_datetime'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_of_the_week_kernel(day, month, year, day_of_week):\n",
    "    for i, (d_1, m_1, y_1) in enumerate(zip(day, month, year)):\n",
    "        if month[i] < 3:\n",
    "            shift = month[i]\n",
    "        else:\n",
    "            shift = 0\n",
    "        Y = year[i] - (month[i] < 3)\n",
    "        y = Y - 2000\n",
    "        c = 20\n",
    "        d = day[i]\n",
    "        m = month[i] + shift + 1\n",
    "        day_of_week[i] = (d + math.floor(m * 2.6) + y + (y // 4) + (c // 4) - 2 * c) % 7\n",
    "        \n",
    "taxi_gdf = taxi_gdf.apply_rows(\n",
    "        day_of_the_week_kernel\n",
    "        , incols = ['day', 'month', 'year']\n",
    "        , outcols = {'day_of_week': np.int32}\n",
    "        , kwargs = {}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_gdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistical Data Science\n",
    "\n",
    "### Look at some feature - by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Let's look at a plot of fare by hour\n",
    "%matplotlib inline\n",
    "taxi_gdf.groupby('hour').fare_amount.mean().to_pandas().sort_index().plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Tips by hour\n",
    "%matplotlib inline\n",
    "taxi_gdf.groupby('hour').tip_amount.mean().to_pandas().sort_index().plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Number of taxi rides by Hour\n",
    "%matplotlib inline\n",
    "taxi_gdf['hour'].groupby(taxi_gdf['hour']).count().to_pandas().sort_index().plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what days are the busiest\n",
    "%matplotlib inline\n",
    "taxi_gdf.groupby('day_of_week').day_of_week.count().to_pandas().sort_index().plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What days have the best tips\n",
    "%matplotlib inline\n",
    "taxi_gdf.groupby('day_of_week').tip_amount.mean().to_pandas().sort_index().plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_gdf = taxi_gdf.drop('store_and_fwd_flag', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_gdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# cuGraph - Accelerated Graph Analytics\n",
    "\n",
    "We need vertex IDs to be integer values but what we have are lat-long pairs (float64).  There are two way that we can address the issue. The hard way and an easy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cugraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_subset = taxi_gdf[['pickup_longitude', 'pickup_latitude','dropoff_longitude', 'dropoff_latitude', 'trip_distance']].reset_index()\n",
    "taxi_subset['count'] = 1\n",
    "del taxi_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vertices and edges the hard way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create node ID from lat-long combinatiuons\n",
    "nodes = [\n",
    "      taxi_subset[['pickup_longitude', 'pickup_latitude']].drop_duplicates().rename(columns={'pickup_longitude': 'long', 'pickup_latitude': 'lat'})\n",
    "    , taxi_subset[['dropoff_longitude', 'dropoff_latitude']].drop_duplicates().rename(columns={'dropoff_longitude': 'long', 'dropoff_latitude': 'lat'})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = cudf.concat(nodes).drop_duplicates().reset_index(drop=True).reset_index().rename(columns={'index': 'id'})\n",
    "nodes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of geo points in the dataset: {0:,}'.format(len(nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = (\n",
    "    taxi_subset[['pickup_longitude', 'pickup_latitude','dropoff_longitude', 'dropoff_latitude', 'trip_distance']]\n",
    "    .drop_duplicates()\n",
    "    .rename(columns={'pickup_longitude': 'long', 'pickup_latitude': 'lat'})\n",
    "    .merge(nodes, on=['lat', 'long'])\n",
    "    .rename(columns={'long': 'pickup_longitude', 'lat': 'pickup_latitude', 'id': 'pickup_id', 'dropoff_longitude': 'long', 'dropoff_latitude': 'lat'})\n",
    "    .merge(nodes, on=['lat', 'long'])\n",
    "    .rename(columns={'long': 'dropoff_longitude', 'lat': 'dropoff_latitude', 'id': 'dropoff_id'})\n",
    ")[['pickup_id', 'dropoff_id', 'trip_distance']]\n",
    "\n",
    "edges.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = cugraph.Graph()\n",
    "g.from_cudf_edgelist(edges, source='pickup_id', destination='dropoff_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "page = cugraph.pagerank(g, alpha=.85, max_iter=1000, tol=1.0e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.sort_values(by='pagerank', ascending=False).head(5).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the easy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = cugraph.Graph()\n",
    "g2.from_cudf_edgelist(taxi_subset, \n",
    "                      source=['pickup_longitude', 'pickup_latitude'], \n",
    "                      destination=['dropoff_longitude', 'dropoff_latitude'], \n",
    "                      edge_attr='count',\n",
    "                      renumber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = cugraph.pagerank(g2, alpha=.85, max_iter=1000, tol=1.0e-05)\n",
    "page.sort_values(by='pagerank', ascending=False).head(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8d149d24ac37d780c569316d1ad317c004152b8897bba41e96412d0cd60b1d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
